---
title: Small sample methods for cluster-robust variance estimation and hypothesis testing in fixed effects models
blinded: 0
authors:
  - name: James E. Pustejovsky
    affiliation: University of Wisconsin - Madison
    thanks: "Department of Educational Psychology, University of Wisconsin - Madison, 1025 West Johnson Street, Madison, WI 53706. Email: pustejovsky@wisc.edu"
  - name: Elizabeth Tipton
    affiliation: Northwestern University
    thanks: "Department of Statistics, Northwestern University. Email: tipton@northwestern.edu"
abstract: |
  In panel data models and other regressions with unobserved effects, fixed effects estimation is often paired with cluster-robust variance estimation (CRVE) in order to account for heteroskedasticity and un-modeled dependence among the errors. 
  Although asymptotically consistent, CRVE can be biased downward when the number of clusters is small, leading to hypothesis tests with rejection rates that are too high. 
  More accurate tests can be constructed using bias-reduced linearization (BRL), which corrects the CRVE based on a working model, in conjunction with a Satterthwaite approximation for t-tests. 
  We propose a generalization of BRL that can be applied in models with arbitrary sets of fixed effects, where the original BRL method is undefined, and describe how to apply the method when the regression is estimated after absorbing the fixed effects. 
  We also propose a small-sample test for multiple-parameter hypotheses, which generalizes the Satterthwaite approximation for t-tests. 
  In simulations covering a wide range of scenarios, we find that the conventional cluster-robust Wald test can severely over-reject while the proposed small-sample test maintains Type I error close to nominal levels. 
  The proposed methods are implemented in an R package called clubSandwich. 
keywords:
  - cluster dependence
  - fixed effects
  - robust standard errors
  - small samples
bibliography: bibliography.bib
biblio-style: agsm
keep_tex: yes
output: 
  rticles::asa_article: default
header-includes:
- \usepackage{amsthm}
- \newtheorem{thm}{Theorem}
- \newtheorem{lem}{Lemma}
- \usepackage{booktabs}
- \usepackage{longtable}
- \usepackage{float}    % for fig.pos='H'
- \usepackage{rotfloat} % for sidewaysfigure
- \hypersetup{hidelinks}
- \newcommand{\Prob}{\text{Pr}}
- \newcommand{\E}{\text{E}}
- \newcommand{\Cov}{\text{Cov}}
- \newcommand{\corr}{\text{corr}}
- \newcommand{\Var}{\text{Var}}
- \newcommand{\iid}{\stackrel{\text{iid}}{\sim}}
- \newcommand{\tr}{\text{tr}}
- \newcommand{\bm}{\mathbf}
- \newcommand{\bs}{\boldsymbol}
---

# INTRODUCTION {#sec:intro}

In many economic analyses, interest centers on the parameters of a linear regression model estimated by ordinary or weighted least squares from data exhibiting within-group dependence. 
Such dependence can arise from sampling or random assignment of aggregate units (e.g., counties, districts, villages), each of which contains multiple observations; from repeated measurement of an outcome on a common set of units, as in panel data; or from model misspecification, as in analysis of regression discontinuity designs [e.g.,@Lee2008regression]. 
A common approach to inference in these settings is to use a cluster-robust variance estimator [CRVE, @Arellano1987computing; @Liang1986longitudinal; @white1984asymptotic].
The advantage of the CRVE is that it produces consistent standard errors and test statistics without imposing strong parametric assumptions about the correlation structure of the errors in the model.
Instead, the method relies on the weaker assumption that units can be grouped into clusters that are mutually independent. 
In the past decade, use of CRVEs has become standard practice for micro-economic researchers, as evidenced by coverage in major textbooks and review articles [e.g., @Wooldridge2010econometric; @Angrist2009mostly; @Cameron2015practitioners].

As a leading example, consider a difference-in-differences analysis of state-by-year panel data, where the goal is to understand the effects on employment outcomes of several state-level policy shifts. 
Each policy effect would be parameterized as a dummy variable in a regression model, which might also include other demographic controls. It is also common to include fixed effects for states and time-points in order to control for unobserved confounding in each dimension. 
The model could be estimated by least squares with the fixed effects included as dummy variables (or what we will call the LSDV estimator). More commonly, the effects of the policy indicators would be estimated after absorbing the fixed effects, a computational technique that is also known as the fixed effects estimator or "within transformation" [@Wooldridge2010econometric]. 
Standard errors would then be clustered by state to account for residual dependence in the errors from a given state, and these clustered standard errors would be used to test hypotheses about the set of policies.
The need to cluster the standard errors by state, even when including state fixed effects, was highlighted by @Bertrand2004how, who showed that to do otherwise can lead to inappropriately small standard errors and hypothesis tests with incorrect rejection rates. 

The consistency property of CRVEs is asymptotic in the number of independent clusters [@Wooldridge2003cluster].
Recent methodological work has demonstrated that CRVEs can be biased downward and associated hypothesis tests can have Type-I error rates considerably in excess of nominal levels when based on a small or moderate number of clusters [e.g.,@MacKinnon2016wild].
@Cameron2015practitioners provided an extensive review of this literature, including a discussion of current practice, possible solutions, and open problems. 
In particular, they demonstrated that small-sample corrections for t-tests implemented in common software packages such as Stata and SAS do not provide adequate control of Type-I error. 

@Bell2002bias proposed a method that improves the small-sample properties of CRVEs [see also @McCaffrey2001generalizations]. 
The method, called bias-reduced linearization (BRL), entails adjusting the CRVE so that it is exactly unbiased under a working model specified by the analyst, while also remaining asymptotically consistent under arbitrary true variance structures. 
Simulations reported by @Bell2002bias demonstrate that the BRL correction serves to reduce the bias of the CRVE even when the working model is misspecified. 
The same authors also proposed small-sample corrections to single-parameter hypothesis tests using the BRL variance estimator, based on Satterthwaite [@Bell2002bias] or saddlepoint approximations [@McCaffrey2006improved]. 
In an analysis of a longitudinal cluster-randomized trial with 35 clusters, @Angrist2009effects observed that the BRL correction makes a difference for inferences. 

Despite a growing body of evidence that BRL performs well [e.g., @Imbens2015robust], several problems with the method hinder its wider application. 
First, @Angrist2009mostly noted that the BRL correction is undefined in some commonly used models, such as state-by-year panels that include fixed effects for states and for years [see also @Young2016improved].
Second, in models with fixed effects, the magnitude of the BRL adjustment depends on whether it is computed based on the full design matrix (i.e., the LSDV estimator) or after absorbing the fixed effects.
Third, extant methods for hypothesis testing based on BRL are limited to single-parameter constraints [@Bell2002bias; @McCaffrey2006improved] and small-sample methods for multiple-parameter hypothesis tests remain lacking.

This paper addresses each of these concerns in turn, with the aim of extending the BRL method so that is suitable for general application. 
First, we describe a simple modification of the BRL adjustment that remains well-defined in models with arbitrary sets of fixed effects, where existing BRL adjustments break down. 
Second, we demonstrate how to calculate the BRL adjustments based on the fixed effects estimator and identify conditions under which first-stage absorption of the fixed effects can be ignored.
Finally, we propose a procedure for testing multiple-parameter hypotheses by approximating the sampling distribution of the Wald statistic using Hotelling's $T^2$ distribution with estimated degrees of freedom. 
The method is a generalization of the Satterthwaite correction proposed by @Bell2002bias for single parameter constraints. 
The proposed methods are implemented in the R package \texttt{clubSandwich}, which is available on the Comprehensive R Archive Network.

Our work is related to a stream of recent literature that has examined methods for cluster-robust inference with a small number of clusters. 
@Conley2011inference proposed methods for hypothesis testing in a difference-in-differences setting where the number of treated units is small and fixed, while the number of untreated units increases asymptotically. 
Ibragimov and M&uuml;ller [-@Ibragimov2010tstatistic; -@Ibragimov2016inference] proposed cluster-robust t-tests that maintain the nominal Type-I error rate by re-weighting within-cluster estimators of the target parameter.
@Young2016improved proposed a Satterthwaite correction for t-tests based on a different type of bias correction to the CRVE, where the bias correction term is derived under a working model.
@Cameron2008bootstrap investigated a range of bootstrapping procedures that provide improved Type-I error control in small samples, finding that a cluster wild-bootstrap technique was particularly accurate in small samples. 
Nearly all of this work has focused on single-parameter hypothesis tests only. 
For multiple-parameter constraints, @Cameron2015practitioners suggested an ad hoc degrees of freedom adjustment and noted, as an alternative, that bootstrapping techniques can in principle be applied to multiple-parameter tests. 
However, little methodological work has examined the accuracy of multiple-parameter tests.

The paper is organized as follows. The remainder of this section introduces our econometric framework and reviews standard CRVE methods, as implemented in most software applications.
Section \ref{sec:BRL} reviews the original BRL correction and describes modifications that make it possible to implement BRL in a broad class of models with fixed effects.
Section \ref{sec:testing} discusses hypothesis tests based on the BRL-adjusted CRVE. 
Section \ref{sec:simulation} reports a simulation study examining the null rejection rates of multiple-parameter hypothesis tests, where we find that the small-sample test offers drastic improvements over commonly implemented alternatives. 
Section \ref{sec:examples} illustrates the use of the proposed hypothesis tests in two applications. 
Section \ref{sec:conclusion} concludes and discusses avenues for future work. 

## Econometric framework

We consider a linear regression model of the form,
\begin{equation}
\label{eq:fixed_effects}
\bm{y}_i = \bm{R}_i \bs\beta + \bm{S}_i \bs\gamma + \bm{T}_i \bs\mu + \bs\epsilon_i,
\end{equation}
where there are a total of $m$ clusters; cluster $i$ contains $n_i$ units; $\bm{y}_i$ is a vector of the $n_i$ values of the outcome for units in cluster $i$;  $\bm{R}_i$ is an $n_i \times r$ matrix containing predictors of primary interest (e.g., policy variables) and any additional controls; $\bm{S}_i$ is an $n_i \times s$ matrix describing fixed effects that are identified across multiple clusters; and $\bm{T}_i$ is an $n_i \times t$ matrix describing cluster-specific fixed effects, which must satisfy $\bm{T}_h \bm{T}_i' = \bm{0}$ for $h \neq i$.
Note that the distinction between the covariates $\bm{R}_i$ versus the fixed effects $\bm{S}_i$ is arbitrary and depends on the analyst's inferential goals.
In a fixed effects model for state-by-year panel data, $\bm{R}_i$ would include variables describing policy changes, as well as additional demographic controls; $\bm{S}_i$ would include year fixed effects; and $\bm{T}_i$ would indicate state fixed effects (and perhaps also state-specific time trends). 
Interest would center on testing hypotheses regarding the coefficients in $\bs\beta$ that correspond to the policy indicators, while $\bs\gamma$ and $\bs\mu$ would be treated as incidental. 

We shall assume that $\E\left(\bs\epsilon_i\left|\bm{R}_i,\bm{S}_i, \bm{T}_i\right.\right) = \bm{0}$ and $\Var\left(\bs\epsilon_i\left|\bm{R}_i,\bm{S}_i,\bm{T}_i\right.\right) = \bs\Sigma_i$, for $i = 1,...,m$, where the form of $\bs\Sigma_1,...,\bs\Sigma_m$ may be unknown but the errors are independent across clusters. 
Let $\bm{U}_i = \left[\bm{R}_i \ \bm{S}_i \right]$ denote the set of predictors that are identified across multiple clusters, $\bm{X}_i = \left[\bm{R}_i \ \bm{S}_i \ \bm{T}_i \right]$ denote the full set of predictors, $\bs\alpha = \left(\bs\beta', \bs\gamma', \bs\mu' \right)'$, and $p = r + s + t$.
Let $N = \sum_{i=1}^m n_i$ denote the total number of observations.
Let $\bm{y}$, $\bm{R}$, $\bm{S}$, $\bm{T}$, $\bm{U}$, $\bm{X}$, and $\bs\epsilon$ denote the matrices obtained by stacking their corresponding components, as in $\bm{R} = \left(\bm{R}_1' \ \bm{R}_2' \ \cdots \ \bm{R}_m'\right)'$. 

We assume that $\bs\beta$ is estimated by weighted least squares (WLS) using symmetric, full rank weighting matrices $\bm{W}_1,...,\bm{W}_m$. 
Clearly, the WLS estimator includes ordinary least squares (OLS) as a special case.
More generally, the WLS estimator encompasses feasible generalized least squares, where it is assumed that $\Var\left(\bm{e}_i\left|\bm{X}_i\right.\right) = \bs\Phi_i$, a known function of a low-dimensional parameter. 
For example, an auto-regressive error structure might be posited to describe repeated measures on an individual over time. 
The weighting matrices are then taken to be $\bm{W}_i = \hat{\bs\Phi}_i^{-1}$, where the $\hat{\bs\Phi}_i$ are constructed from estimates of the variance parameter.
Finally, for analysis of data from complex survey designs, WLS may be used with sampling weights in order to account for unequal selection probabilities.

## Absorption

The goal of most analyses is to estimate and test hypotheses regarding the parameters in $\bs\beta$, while the fixed effects $\bs\gamma$ and $\bs\mu$ are not of inferential interest. Furthermore, LSDV estimation becomes computationally intensive and numerically inaccurate if the model includes a large number of fixed effects (i.e., $s + t$ large). 
A commonly implemented alternative to LSDV is to first absorb the fixed effects, which leaves only the $r$ parameters in $\bs\beta$ to be estimated. 
Because Section \ref{sec:BRL} examines the implications of absorption for application of the BRL adjustment, we now formalize this procedure.
Denote the full block-diagonal weighting matrix as $\bm{W} = \text{diag}\left(\bm{W}_1,...,\bm{W}_m\right)$.
Let $\bm{K}$ be the $p \times r$ matrix that selects the covariates of interest, so that $\bm{X} \bm{K} = \bm{R}$ and $\bm{K}'\bs\alpha = \bs\beta$.
For a generic matrix $\bm{Z}$ of full column rank, let $\bm{M_Z} = \left(\bm{Z}'\bm{W}\bm{Z}\right)^{-1}$ and $\bm{H_Z} = \bm{Z}\bm{M_Z}\bm{Z}'\bm{W}$. 

The absorption technique involves obtaining the residuals from the regression of $\bm{y}$ on $\bm{T}$ and from the multivariate regression of $[\bm{R} \ \bm{S}]$ on $\bm{T}$. 
The $\bm{y}$ residuals and $\bm{R}$ residuals are then regressed on the $\bm{S}$ residuals. 
Finally, these twice-regressed $\bm{y}$ residuals are regressed on the twice-regressed $\bm{R}$ residuals to obtain the WLS estimates of $\bs\beta$. 
Let $\bm{\ddot{S}} = \left(\bm{I} - \bm{H_T}\right)\bm{S}$, $\bm{\ddot{R}} = \left(\bm{I} - \bm{H_{\ddot{S}}}\right)\left(\bm{I} - \bm{H_T}\right)\bm{R}$, and $\bm{\ddot{y}} = \left(\bm{I} - \bm{H_{\ddot{S}}}\right)\left(\bm{I} - \bm{H_T}\right)\bm{y}$. 
In what follows, subscripts on $\bm{\ddot{R}}$, $\bm{\ddot{S}}$,  $\bm{\ddot{U}}$, and $\bm{\ddot{y}}$ refer to the rows of these matrices corresponding to a specific cluster. 
The WLS estimator of $\bs\beta$ can then be written as
\begin{equation}
\label{eq:WLS}
\bs{\hat\beta} = \bm{M_{\ddot{R}}} \sum_{i=1}^m \bm{\ddot{R}}_i' \bm{W}_i \bm{\ddot{y}}_i. 
\end{equation}
This estimator is algebraically identical to the LSDV estimator, $\bs{\hat\beta} = \bm{K}'\bm{M_X} \bm{X}' \bm{W} \bm{y}$, but avoids the need to solve a system of $p$ linear equations. For further details on sequential absorption, see \citet{Davis2002estimating}. In the remainder, we assume that fixed effects are absorbed before estimation of $\bs\beta$. 

## Standard CRVE

The WLS estimator $\bs{\hat\beta}$, has true variance
\begin{equation}
\label{eq:var_WLS}
\Var\left(\bs{\hat\beta}\right) = \bm{M_{\ddot{R}}}\left(\sum_{i=1}^m \bm{\ddot{R}}_i' \bm{W}_i \bs\Sigma_i \bm{W}_i\bm{\ddot{R}}_i\right) \bm{M_{\ddot{R}}},
\end{equation}
which depends upon the unknown variance matrices $\bs\Sigma_i$. 

The CRVE involves estimating $\Var\left(\bs{\hat\beta}\right)$ empirically, without imposing structural assumptions on $\bs\Sigma_i$. 
There are several versions of this approach, all of which can be written as
\begin{equation}
\label{eq:V_small}
\bm{V}^{CR} = \bm{M_{\ddot{R}}}\left(\sum_{i=1}^m \bm{\ddot{R}}_i'\bm{W}_i \bm{A}_i \bm{e}_i \bm{e}_i' \bm{A}_i' \bm{W}_i \bm{\ddot{R}}_i\right) \bm{M_{\ddot{R}}},
\end{equation}
where $\bm{e}_i = \bm{Y}_i - \bm{X}_i \bs{\hat\beta}$ is the vector of residuals from cluster $i$ and $\bm{A}_i$ is some $n_i$ by $n_i$ adjustment matrix. 

The form of the adjustment matrices parallels those of the heteroskedasticity-consistent variance estimators proposed by @MacKinnon1985some. 
The original CRVE, described by @Liang1986longitudinal, uses $\bm{A}_i = \bm{I}_i$, an $n_i \times n_i$ identity matrix. 
Following @Cameron2015practitioners, we refer to this estimator as CR0. 
This estimator is biased towards zero because the cross-product of the residuals $\bm{e}_i \bm{e}_i'$ tends to under-estimate the true variance $\bs\Sigma_i$ in cluster $i$.
A rough bias adjustment is to take $\bm{A}_i = c\bm{I}_i$, where $c = \sqrt{(m/(m-1))}$; we denote this adjusted estimator as CR1. Some functions in Stata use a slightly different correction factor $c_S = \sqrt{(m N)/[(m - 1)(N - p)]}$; we will refer to the adjusted estimator using $c_S$ as CR1S. When $N >> p$, $c_S \approx \sqrt{m/(m-1)}$ and so CR1 and CR1S will be very similar. 
However, CR1 and CR1S can differ quite substantially for models with a large number of fixed effects and small within-cluster sample size; recent guidance emphasizes that CR1S is not appropriate for this scenario @Cameron2015practitioners.
The CR1 and CR1S estimators are commonly used in empirical applications.

Use of these adjustments still tends to under-estimate the true variance of $\hat{\bs\beta}$ because the degree of bias depends not only on the number of clusters $m$, but also on skewness of the covariates and unbalance across clusters [@Carter2013asymptotic; @MacKinnon2013thirty; @Cameron2015practitioners; @Young2016improved]. 
A more principled approach to bias correction would take into account the features of the covariates in $\bm{X}$. 
One such estimator uses adjustment matrices given by $\bm{A}_i = \left(\bm{I} - \bm{\ddot{R}}_i \bm{M_{\ddot{R}}}\bm{\ddot{R}}_i'\bm{W}_i\right)^{-1}$. This estimator, denoted CR3, closely approximates the jackknife re-sampling estimator [@Bell2002bias; @Mancl2001covariance].  
However, CR3 tends to over-correct the bias of CR0, while the CR1 estimator tends to under-correct. 
The next section describes in detail the BRL approach, which makes adjustments that are intermediate in magnitude between CR1 and CR3. 

# BIAS REDUCED LINEARIZATION {#sec:BRL}

The BRL correction is premised on a "working" model for the structure of the errors, which must be specified by the analyst. 
Under a given working model, adjustment matrices $\bm{A}_i$ are defined so that the variance estimator is exactly unbiased.
We refer to this correction as CR2 because it extends the HC2 variance estimator for regressions with uncorrelated errors, which is exactly unbiased when the errors are homoskedastic [@MacKinnon1985some].
The idea of specifying a model may seem antithetical to the purpose of using CRVE, yet extensive simulation studies have demonstrated that the method performs well in small samples even when the working model is incorrect [@Tipton2015small-t; @Bell2002bias; @Cameron2015practitioners; @Imbens2015robust]. 
Although the CR2 estimator might not be exactly unbiased when the working model is misspecified, its bias still tends to be greatly reduced compared to CR1 or CR0 (thus the name "bias reduced linearization"). Furthermore, as the number of clusters increases, reliance on the working model diminishes. 

Let $\bs\Phi = \text{diag}\left(\bs\Phi_1,...,\bs\Phi_m\right)$ denote a working model for the covariance structure (up to a scalar constant). 
For example, we might assume that the errors are uncorrelated and homoskedastic, with $\bs\Phi_i = \bm{I}_i$ for $i = 1,...,m$. 
Alternatively, @Imbens2015robust suggested using a random effects (i.e., compound symmetric) structure, in which $\bs\Phi_i$ has unit diagonal entries and off-diagonal entries of $\rho$, with $\rho$ estimated using the OLS residuals.

In the original formulation of @Bell2002bias, the BRL adjustment matrices are chosen to satisfy the criterion
\begin{equation}
\label{eq:CR2_criterion_BM}
\bm{A}_i \left(\bm{I} - \bm{H_X}\right)_i \bs\Phi \left(\bm{I} - \bm{H_X}\right)_i' \bm{A}_i'  =  \bs\Phi_i 
\end{equation}
for a given working model, where $\left(\bm{I} - \bm{H_X}\right)_i$ denotes the rows of $\bm{I} - \bm{H_X}$ corresponding to cluster $i$.
If the working model and weight matrices are both taken to be identity matrices, then the adjustment matrices simplify to $\bm{A}_i =  \left(\bm{I}_i - \bm{\ddot{U}}_i \bm{M_{\ddot{U}}} \bm{\ddot{U}}_i'\right)^{-1/2}$, where $\bm{Z}^{-1/2}$ denotes the symmetric square-root of the matrix $\bm{Z}$. 

## A more general BRL criterion

The original formulation of $\bm{A}_i$ is problematic because, for some fixed effects models that are common in economic applications, Equation \ref{eq:CR2_criterion_BM} has no solution. 
@Angrist2009mostly note that this problem occurs in balanced state-by-year panel models that include fixed effects for states and for years, where $\bm{I}_i - \bm{\ddot{U}}_i \bm{M_{\ddot{U}}} \bm{\ddot{U}}_i'$ is not of full rank. 
@Young2016improved reported that this problem occurred frequently when applying BRL to a large corpus of fitted regression models drawn from published studies.

This issue can be solved by using an alternative criterion to define the adjustment matrices, for which a solution always exists. 
Instead of (\ref{eq:CR2_criterion_BM}), we propose to use adjustment matrices $\bm{A}_i$ that satisfy:
\begin{equation}
\label{eq:CR2_criterion}
\bm{\ddot{R}}_i' \bm{W}_i \bm{A}_i \left(\bm{I} - \bm{H_X}\right)_i \bs\Phi \left(\bm{I} - \bm{H_X}\right)_i' \bm{A}_i' \bm{W}_i \bm{\ddot{R}}_i = \bm{\ddot{R}}_i' \bm{W}_i \bs\Phi_i \bm{W}_i \bm{\ddot{R}}_i.
\end{equation}
A variance estimator that uses such adjustment matrices will be exactly unbiased when the working model is correctly specified.

A symmetric solution to Equation (\ref{eq:CR2_criterion}) is given by
\begin{equation}
\label{eq:CR2_adjustment}
\bm{A}_i = \bm{D}_i' \bm{B}_i^{+1/2} \bm{D}_i,
\end{equation}
where $\bm{D}_i$ is the upper-right triangular Cholesky factorization of $\bs\Phi_i$, 
\begin{equation}
\label{eq:CR2_Bmatrix}
\bm{B}_i = \bm{D}_i\left(\bm{I} - \bm{H_X}\right)_i \bs\Phi \left(\bm{I} - \bm{H_X}\right)_i' \bm{D}_i',
\end{equation}
and $\bm{B}_i^{+1/2}$ is the symmetric square root of the Moore-Penrose inverse of $\bm{B}_i$. 
The Moore-Penrose inverse of $\bm{B}_i$ is well-defined and unique [@Banerjee2014linear, Thm. 9.18].
In contrast, the original BRL adjustment matrices involve the symmetric square root of the regular inverse of $\bm{B}_i$, which does not exist when $\bm{B}_i$ is rank-deficient. If $\bm{B}_i$ is of full rank, then our adjustment matrices reduce to the original formulation described by @Bell2002bias. 

The adjustment matrices given by (\ref{eq:CR2_adjustment}) and (\ref{eq:CR2_Bmatrix}) satisfy criterion (\ref{eq:CR2_criterion}), as stated in the following theorem.

\begin{thm}
\label{thm:BRL_FE}
Let $\bm{L}_i = \left(\bm{\ddot{U}}'\bm{W}\bm{\ddot{U}} - \bm{\ddot{U}}_i'\bm{W}_i\bm{\ddot{U}}_i\right)$, where $\bm{\ddot{U}} = \left(\bm{I} - \bm{H_T}\right)\bm{U}$, and assume that $\bm{L}_1,...,\bm{L}_m$ have full rank $r + s$. Further assume that $\Var\left(\bs\epsilon_i\left|\bm{X}_i\right.\right) = \sigma^2 \bs\Phi_i$, for $i = 1,...,m$. Then the adjustment matrix $\bm{A}_i$ defined in (\ref{eq:CR2_adjustment}) and (\ref{eq:CR2_Bmatrix}) satisfies criterion (\ref{eq:CR2_criterion}) and the CR2 variance estimator is exactly unbiased.
\end{thm}

Proof is given in the supplementary materials. The main implication of Theorem \ref{thm:BRL_FE} is that, under our more general definition, the CR2 variance estimator remains well-defined even in models with large sets of fixed effects.

## Absorption and LSDV Equivalence

In fixed effects regression models, a problem with the original definition of BRL is that it can result in a different estimator depending upon which design matrix is used.
If $\bs\beta$ is estimated using LSDV, then it is natural to calculate the CR2 adjustment matrices based on the full covariate design matrix, $\bm{X}$. However, if $\bs\beta$ is estimated after absorbing the fixed effects, the analyst might choose to calculate the CR2 correction based on the absorbed covariate matrix $\bm{\ddot{R}}$---that is, by substituting $\bm{H_{\ddot{R}}}$ for $\bm{H_X}$ in (\ref{eq:CR2_Bmatrix})---in order to avoid calculating the full projection matrix $\bm{H_X}$. 
This approach can lead to different adjustment matrices because it is based on a subtly different working model. 
Essentially, calculating CR2 based on $\bm{H_{\ddot{R}}}$ amounts to assuming that the working model $\bs\Phi$ applies not to the model errors $\bs\epsilon$, but rather to the errors from the final-stage regression of $\bm{\ddot{y}}$ on $\bm{\ddot{R}}$.
Because the CR2 adjustment is relatively insensitive to the working model, the difference between accounting for or ignoring absorption will in many instances be small. 
We investigate the differences between the approaches as part of the simulation study in Section \ref{sec:simulation}.

When based on the full regression model, a drawback of using the CR2 adjustment matrices is that it entails calculating the projection matrix $\bm{H_X}$ for the full set of $p$ covariates (i.e., including fixed effect indicators). 
Given that the entire advantage of using absorption to calculate $\hat{\bs\beta}$ is to avoid computations involving large, sparse matrices, it is of interest to find methods for more efficiently calculating the CR2 adjustment matrices. 
Some computational efficiency can be gained by using the fact that the residual projection matrix $\bm{I} - \bm{H_X}$ can be factored into components as $\left(\bm{I} - \bm{H_X}\right)_i = \left(\bm{I} - \bm{H_{\ddot{R}}}\right)_i \left(\bm{I} - \bm{H_{\ddot{S}}}\right) \left(\bm{I} - \bm{H_T}\right)$.

In certain circumstances, further computational efficiency can be achieved by computing the adjustment matrices after absorbing the within-cluster fixed effects $\bm{T}$ (but not the between-cluster fixed effects $\bm{S}$). 
Specifically, if the weights used for WLS estimation are the inverses of the working covariance model, so that $\bm{W}_i = \bs\Phi_i^{-1}$ for $i = 1,...,m$, then the adjustment matrices can be calculated without accounting for the within-cluster fixed effects. 
This result is formalized in the following theorem.  

\begin{thm}
\label{thm:absorb}
Let $\bm{\tilde{A}}_i = \bm{D}_i'\bm{\tilde{B}}_i^{+1/2} \bm{D}_i$, where 
\begin{equation}
\label{eq:CR2_B_tilde}
\bm{\tilde{B}}_i = \bm{D}_i\left(\bm{I} - \bm{H_{\ddot{R}}}\right)_i \left(\bm{I} - \bm{H_{\ddot{S}}}\right) \bs\Phi \left(\bm{I} - \bm{H_{\ddot{S}}}\right)' \left(\bm{I} - \bm{H_{\ddot{R}}}\right)_i' \bm{D}_i'.
\end{equation}
If $\bm{W} = \bs\Phi^{-1}$ and $\bm{T}_i \bm{T}_k' = \bm{0}$ for $i \neq k$, then $\bm{A}_i = \bm{\tilde{A}}_i$. 
\end{thm}

Proof is given in the supplementary materials.
The main implication of Theorem \ref{thm:absorb} is that the more computationally tractable formula $\bm{\tilde{B}}_i$ can be used in the common case that the weighting matrices are the inverse of the working covariance model.
Following the working model suggested by @Bell2002bias, in which $\bs\Phi = \bm{I}$, the theorem shows that the adjustment method is invariant to the choice of estimator so long as the model is estimated by OLS (i.e., with $\bm{W} = \bm{I}$).
<!-- In this case, the CR2 adjustment matrices then simplify further to $\bm{A}_i = \left(\bm{I}_i - \bm{\ddot{U}}_i\left(\bm{\ddot{U}}'\bm{\ddot{U}}\right)^{-1}\bm{\ddot{U}}_i'\right)^{+1/2}$. -->
In contrast, if the working model proposed by @Imbens2015robust is instead used (while still using OLS), then the the CR2 adjustments might differ depending on whether LSDV or the fixed effects estimator is used.

# HYPOTHESIS TESTING {#sec:testing}

The CR2 correction produces a CRVE that has reduced bias (compared to other CRVEs) when the number of clusters is small, leading to more accurate standard errors. However, standard errors are of limited inherent interest. Rather, their main use is for the construction of hypothesis tests and confidence intervals, which are often based on Wald-type test statistics.

Cluster-robust Wald tests are justified on an asymptotic basis as the number of clusters grows large. 
Evidence from a wide variety of contexts indicates that the asymptotic limiting distribution of robust Wald statistics can be a poor approximation when the number of clusters is small, even if corrections such as CR2 or CR3 are employed \citep{Bell2002bias, Bertrand2004how, Cameron2008bootstrap}. 
Like the bias of the CRVE estimator itself, the accuracy of the asymptotic approximations depends on design features such as the degree of imbalance across clusters, skewness or leverage of the covariates, and the similarity of cluster sizes \citep[][\maskcitealp{Tipton2015small-F}]{McCaffrey2001generalizations, MacKinnon2016wild, Carter2013asymptotic}. 
This suggests that, if hypothesis tests are to achieve accurate rejection rates in small samples, they should account for features of the design matrix.

In this section, we develop a method for testing linear constraints on $\bs\beta$, where the null hypothesis has the form $H_0: \bm{C}\bs\beta = \bm{d}$ for fixed $q \times r$ matrix $\bm{C}$ and $q \times 1$ vector $\bm{d}$. 
The cluster-robust Wald statistic is then
\begin{equation}
\label{eq:Wald_stat}
Q = \left(\bm{C}\bs{\hat\beta} - \bm{d}\right)'\left(\bm{C} \bm{V}^{CR} \bm{C}'\right)^{-1}\left(\bm{C}\bs{\hat\beta} - \bm{d}\right),
\end{equation}
where $\bm{V}^{CR}$ is one of the cluster-robust estimators described in previous sections. 
The asymptotic Wald test rejects $H_0$ if $Q$ exceeds the $\alpha$ critical value from a chi-squared distribution with $q$ degrees of freedom. 
It can be shown that this test approaches level $\alpha$ when the number of clusters is large. 
However, in practice it is rarely clear how large a sample is needed for the asymptotic approximation to be accurate. 

## Small-sample corrections for t-tests {#subsec:t-tests}

Consider testing the hypothesis $H_0: \bm{c}'\bs\beta = 0$ for a fixed $r \times 1$ contrast vector $\bm{c}$. 
For this one-dimensional constraint, an equivalent to the Wald statistic given in (\ref{eq:Wald_stat}) is to use the test statistic $Z = \bm{c}'\bs{\hat\beta} / \sqrt{\bm{c}'\bm{V}^{CR}\bm{c}}$, which follows a standard normal distribution in large samples. 
In small samples, it is common to use the CR1 or CR1S estimator and to approximate the distribution of $Z$ by a $t(m - 1)$ distribution. 
\citet{Hansen2007asymptotic} provided one justification for the use of this reference distribution by identifying conditions under which $Z$ converges in distribution to $t(m-1)$ as the within-cluster sample sizes grow large, with $m$ fixed \citep[see also][]{Donald2007inference}. 
\citet{Ibragimov2010tstatistic} proposed a weighting technique derived so that $t(m-1)$ critical values lead to rejection rates less than or equal to $\alpha$.
Both of these arguments require that $\bm{c}'\bs\beta$ be separately identified within each cluster. 
Outside of these circumstances, using $t(m-1)$ critical values can still lead to over-rejection \citep{Cameron2015practitioners}. 
Furthermore, using these critical values does not take into account that the distribution of $\bm{V}^{CR}$ is affected by the structure of $\bm{X}$. 

\citet{Bell2002bias} proposed to compare $Z$ to a $t(\nu)$ references distribution, with degrees of freedom $\nu$ estimated by a Satterthwaite approximation.
The Satterthwaite approximation \citep{Satterthwaite1946approximate} entails using degrees of freedom that are a function of the the first two moments of the sampling distribution of $\bm{c}' \bm{V}^{CR} \bm{c}$.
%Theoretically, these degrees of freedom should be 
%$\nu = 2\left[\E\left(\bm{c}'\bm{V}^{CR2}\bm{c}\right)\right]^2 / \Var\left(\bm{c}'\bm{V}^{CR2}\bm{c}\right)$.
Expressions for the first two moments of $\bm{c}'\bm{V}^{CR2}\bm{c}$ can be derived under the assumption that the errors $\bs\epsilon_1,...,\bs\epsilon_m$ are normally distributed. 
In practice, both moments involve the variance structure $\bs\Sigma$, which is unknown. 
\citet{Bell2002bias} proposed to estimate the moments based on the same working model that is used to derive the adjustment matrices. 
This ``model-assisted'' estimate of the degrees of freedom is then calculated as 
\begin{equation}
\label{eq:nu_model}
\nu_{M} = \frac{\left(\sum_{i=1}^m \bm{p}_i' \bs\Phi \bm{p}_i\right)^2}{\sum_{i=1}^m \sum_{j=1}^m \left(\bm{p}_i' \bs\Phi \bm{p}_j\right)^2},
\end{equation}
where $\bm{p}_i = \left(\bm{I} - \bm{H_X}\right)_i'\bm{A}_i \bm{W}_i\bm{\ddot{R}}_i\bm{M_{\ddot{R}}} \bm{c}$.
This approximation works because the degrees of freedom account for covariate features that affect the distribution of the test statistic. 

Previous simulation studies have examined the performance of t-tests based on the CR2 variance estimator and Satterthwaite approximation under a variety of conditions, including panel data models \citep{Cameron2015practitioners, Imbens2015robust}, analysis of multi-stage surveys \citep{Bell2002bias}, and meta-analysis \maskcitep{Tipton2015small-t}. Across this range of data-generating processes, these studies found that the Type I error rate of the test is nearly always less than or equal to the nominal $\alpha$, so long as the degrees of freedom are larger than 4 or 5 \citep[][\maskcitealp{Tipton2015small-t}]{Bell2002bias}.
%However, when the degrees of freedom are very small, the t-distribution approximation to the sampling distribution does not hold, and the Type I error can be higher than the stated $\alpha$ level.\footnote{When the degrees of freedom are smaller than 4 or 5, \maskcitet{Tipton2015small-t} suggested using a smaller $\bs\alpha$ level for hypothesis testing in order to partially compensate. Another possibility would be to use the saddlepoint approximation proposed by \citet{McCaffrey2006improved}.}
Because the degrees of freedom are covariate-dependent, it is not possible to assess whether a small-sample correction is needed based solely on the total number of clusters in the data. 
Consequently, \maskcitet{Tipton2015small-t} and \citet{Imbens2015robust} argued that t-tests based on CRVE should routinely use the CR2 variance estimator and the Satterthwaite degrees of freedom, even when $m$ appears to be large.

## Small-sample corrections for F-tests {#subsec:F-tests}

Little research has considered small-sample corrections for multiple-constraint hypothesis tests based on cluster-robust Wald statistics.
Cameron and Miller highlighted this problem, noting that some form of adjustment is clearly needed in light of the extensive work on single-parameter tests.
We now describe an approach to multi-parameter testing that closely parallels the Satterthwaite correction for t-tests.

Our approach is to approximate the sampling distribution of $Q$ by Hotelling's $T^2$ distribution (a multiple of an F distribution) with estimated degrees of freedom. To motivate the approximation, let $\bm{G} = \bm{C} \bm{M_{\ddot{R}}}\bm{\ddot{R}}'\bm{W}\bs\Phi\bm{W}\bm{\ddot{R}}\bm{M_{\ddot{R}}} \bm{C}'$ denote the variance of $\bm{C}\bs{\hat\beta}$ under the working model and observe that $Q$ can be written as $Q = \bm{z}' \bs\Omega^{-1} \bm{z}$, where $\bm{z} = \bm{G}^{-1/2}\left(\bm{C}\bs{\hat\beta} - \bm{d}\right)$ and $\bs\Omega = \bm{G}^{-1/2} \bm{C} \bm{V}^{CR}\bm{C}'\bm{G}^{-1/2}$. 
Now suppose that $\eta \times \bs\Omega$ follows a Wishart distribution with $\eta$ degrees of freedom and a $q$-dimensional identity scale matrix. It then follows that
\begin{equation}
\label{eq:AHT}
\left(\frac{\eta - q + 1}{\eta q}\right) Q \ \dot\sim \ F(q, \eta - q + 1).
\end{equation}
We will refer to this as the approximate Hotelling's $T^2$ (AHT) test.
We consider how to estimate $\eta$ below.
Note that this approximation reduces to the Satterthwaite approximation when $q = 1$. 
For $q > 1$, the test depends on the multivariate distribution of $\bm{V}^{CR}$, including both variance and covariance terms. 

\maskcitet{Tipton2015small-F} recently introduced this test for the special case of CRVE for regression models used in meta-analysis.
Wishart approximations have also been considered as approximations in several simpler models where special cases of CRVEs are used.
\citet{Nel1986solution} proposed an AHT-type test for equality of multivariate means across two samples with unequal variance-covariance matrices \citep[i.e., the multivariate Behrens-Fisher problem; see also][]{Krishnamoorthy2004modified}.
\citet{Zhang2012twowayANOVA} followed a similar approach in developing a test for contrasts in multivariate analysis of variance models where the covariance of the errors differs across groups, a special case of model (\ref{eq:fixed_effects}) where the CR2 variance estimator has a particularly simple form. 
In each of these special cases, the robust variance estimator is a mixture of Wishart distributions that is well-approximated by a Wishart distribution with estimated degrees of freedom.
Additionally, \citet{Pan2002small} described an F-test for use in GEE models, which uses the Wishart approximation to the distribution of $\bm{V}^{CR0}$ but estimates the degrees of freedom using a different method than the one we describe below.

In an extensive simulation, \maskcitet{Tipton2015small-F} compared the performance of the AHT test to several other possible approximate F-tests, including adaptations of the tests introduced by \citet{Pan2002small} and \citet{Zhang2012twowayANOVA}, as well as adaptations of tests based on eigen-decompositions proposed by \citet{Fai1996approximate} and \citet{Cai2008new}.
Simulation results indicated that the AHT test presented here has Type I error closer to nominal than any of the other tests across a wide range of parameter values, covariate types, and hypotheses.
The contribution of the present paper is to extend the AHT test to the general setting of linear models with fixed effects and clustered errors. 

The remaining question is how to estimate the parameter $\eta$, which determines the scalar multiplier and denominator degrees of freedom of the AHT test. 
To do so, we match the mean and variance of $\bs\Omega$ to that of the approximating Wishart distribution under the working variance model $\bs\Phi$, just as in the Satterthwaite degrees of freedom approximation for the t-test. 
However, it is not possible to exactly match both moments if $q > 1$.
Following \maskcitet{Tipton2015small-F}, we instead match the mean and total variance of $\bs\Omega$ (i.e., the sum of the variances of its entries).

Let $\bm{g}_1,...,\bm{g}_q$ denote the $q \times 1$ column vectors of $\bm{G}^{-1/2}$. 
Let \[
\bm{p}_{si} = \left(\bm{I} - \bm{H_X}\right)_i' \bm{A}_i \bm{W}_i \bm{\ddot{R}}_i \bm{M_{\ddot{R}}}\bm{C} \bm{g}_s \]
for $s = 1,...,q$ and $i = 1,...,m$.
Under the working model, the degrees of freedom are then approximated as
\begin{equation}
\label{eq:eta_model}
\eta_M = \frac{q(q + 1)}{\sum_{s,t=1}^q \sum_{i,j=1}^m \left(\bm{p}_{si}'\bs\Phi\bm{p}_{tj} \bm{p}_{ti}'\bs\Phi\bm{p}_{sj} + \bm{p}_{si}'\bs\Phi\bm{p}_{sj} \bm{p}_{ti}'\bs\Phi\bm{p}_{tj}\right)}.
\end{equation}
If $q = 1$, then $\eta_M$ reduces to $\nu_M$ from Equation (\ref{eq:nu_model}).

This AHT F-test shares several features with the Satterthwaite approximation for t-tests. As with the t-test, the degrees of freedom of this F-test depend not only on the number of clusters, but also on features of the covariates being tested. 
The degrees of freedom can be much lower than $m - 1$, particularly when the covariates being tested exhibit high leverage or are unbalanced across clusters. 
For example, if the goal is to test if there are differences across a three-arm, block-randomized experiment with clustering by block, the degrees of freedom will be largest (approaching $m - 1$) when the treatment is allocated equally across the three groups within each block. 
If the treatment allocation varies from cluster to cluster, the degrees of freedom will be smaller---even if the total number of clusters is large. 
We thus expect that using the AHT degrees of freedom, which take into account features of the covariate distribution, will improve the accuracy of the rejection rates in small samples. 

\newpage

# References {-}